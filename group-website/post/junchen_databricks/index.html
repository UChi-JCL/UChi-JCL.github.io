<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: May 26, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.7" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  

  

  <link rel="stylesheet" href="/group-website/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/group-website/css/wowchemy.37c3129fa572f6de5ff709e6da9888d2.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/group-website/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/group-website/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  




































  

<meta name="description" content=" Prefill in LLM inference is known to be resource-intensive, especially for long LLM inputs. While better scheduling can mitigate prefill’s impact, it would be fundamentally better to avoid (most of) prefill. This talk introduces our preliminary effort towards drastically minimizing prefill delay for LLM inputs that naturally reuse text chunks, such as in retrieval-augmented generation. While keeping the KV cache of all text chunks in memory is difficult, we show that it is possible to store them on cheaper yet slower storage. By improving the loading process of the reused KV caches, we can still significantly speed up prefill delay while maintaining the same generation quality. &lt;/.p&gt;
Talk link :

Slides link :
    AI/ML Infra Meetup | Reducing Prefill for LLM Serving in RAG   " />



<link rel="alternate" hreflang="en-us" href="https://uchi-jcl.github.io/group-website/post/junchen_databricks/" />
<link rel="canonical" href="https://uchi-jcl.github.io/group-website/post/junchen_databricks/" />



  <link rel="manifest" href="/group-website/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/group-website/media/icon_hua25ef39b30b8f32ff2a6fd2e1eed54f5_1032324_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/group-website/media/icon_hua25ef39b30b8f32ff2a6fd2e1eed54f5_1032324_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@GetResearchDev" />
  <meta property="twitter:creator" content="@GetResearchDev" />
<meta property="twitter:image" content="https://uchi-jcl.github.io/group-website/media/icon_hua25ef39b30b8f32ff2a6fd2e1eed54f5_1032324_512x512_fill_lanczos_center_3.png" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="Junchen&#39;s Lab" />
<meta property="og:url" content="https://uchi-jcl.github.io/group-website/post/junchen_databricks/" />
<meta property="og:title" content="Junchen&#39; talk on the llm caching layer at Databricks and Alluxio’s AI/ML Infra meetup.
 | Junchen&#39;s Lab" />
<meta property="og:description" content=" Prefill in LLM inference is known to be resource-intensive, especially for long LLM inputs. While better scheduling can mitigate prefill’s impact, it would be fundamentally better to avoid (most of) prefill. This talk introduces our preliminary effort towards drastically minimizing prefill delay for LLM inputs that naturally reuse text chunks, such as in retrieval-augmented generation. While keeping the KV cache of all text chunks in memory is difficult, we show that it is possible to store them on cheaper yet slower storage. By improving the loading process of the reused KV caches, we can still significantly speed up prefill delay while maintaining the same generation quality. &lt;/.p&gt;
Talk link :

Slides link :
    AI/ML Infra Meetup | Reducing Prefill for LLM Serving in RAG   " /><meta property="og:image" content="https://uchi-jcl.github.io/group-website/media/icon_hua25ef39b30b8f32ff2a6fd2e1eed54f5_1032324_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2024-05-22T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2024-05-22T00:00:00&#43;00:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://uchi-jcl.github.io/group-website/post/junchen_databricks/"
  },
  "headline": "Junchen' talk on the llm caching layer at Databricks and Alluxio’s AI/ML Infra meetup.\n",
  
  "datePublished": "2024-05-22T00:00:00Z",
  "dateModified": "2024-05-22T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Authors"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Junchen's Lab",
    "logo": {
      "@type": "ImageObject",
      "url": "https://uchi-jcl.github.io/group-website/media/icon_hua25ef39b30b8f32ff2a6fd2e1eed54f5_1032324_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "\u003cp align=\"justify\"\u003e Prefill in LLM inference is known to be resource-intensive, especially for long LLM inputs. While better scheduling can mitigate prefill’s impact, it would be fundamentally better to avoid (most of) prefill. This talk introduces our preliminary effort towards drastically minimizing prefill delay for LLM inputs that naturally reuse text chunks, such as in retrieval-augmented generation. While keeping the KV cache of all text chunks in memory is difficult, we show that it is possible to store them on cheaper yet slower storage. By improving the loading process of the reused KV caches, we can still significantly speed up prefill delay while maintaining the same generation quality. \u003c/.p\u003e\n\u003cp\u003eTalk link :\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/a5YH2RCe4NU?si=7hRisB8JXXl19grx\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\u003cp\u003eSlides link :\u003c/p\u003e\n\u003ciframe src=\"//www.slideshare.net/slideshow/embed_code/key/eOSyDpGElSFWvB\" width=\"560\" height=\"315\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;\" allowfullscreen\u003e \u003c/iframe\u003e \u003cdiv style=\"margin-bottom:5px\"\u003e \u003cstrong\u003e \u003ca href=\"//www.slideshare.net/slideshow/ai-ml-infra-meetup-reducing-prefill-for-llm-serving-in-rag/269308079\" title=\"\" target=\"_blank\"\u003eAI/ML Infra Meetup | Reducing Prefill for LLM Serving in RAG\u003c/a\u003e \u003c/strong\u003e \u003c/strong\u003e \u003c/div\u003e"
}
</script>

  

  




  
  
  

  
  

  


  
  <title>Junchen&#39; talk on the llm caching layer at Databricks and Alluxio’s AI/ML Infra meetup.
 | Junchen&#39;s Lab</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="650226bc0e037496c4e91af613bb222c" >

  
  
  
  
  
  
  
  
  
  <script src="/group-website/js/wowchemy-init.min.4fef3e534144e9903491f0cc6527eccd.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/group-website/">Junchen&#39;s Lab</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/group-website/">Junchen&#39;s Lab</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/group-website/tour"><span>Tour</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/group-website/post"><span>News</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/group-website/people"><span>People</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/group-website/projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/group-website/publication"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/group-website/contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>Junchen&#39; talk on the llm caching layer at Databricks and Alluxio’s AI/ML Infra meetup.
</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    May 22, 2024
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    1 min read
  </span>
  

  
  
  
  

  
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <p align="justify"> Prefill in LLM inference is known to be resource-intensive, especially for long LLM inputs. While better scheduling can mitigate prefill’s impact, it would be fundamentally better to avoid (most of) prefill. This talk introduces our preliminary effort towards drastically minimizing prefill delay for LLM inputs that naturally reuse text chunks, such as in retrieval-augmented generation. While keeping the KV cache of all text chunks in memory is difficult, we show that it is possible to store them on cheaper yet slower storage. By improving the loading process of the reused KV caches, we can still significantly speed up prefill delay while maintaining the same generation quality. </.p>
<p>Talk link :</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/a5YH2RCe4NU?si=7hRisB8JXXl19grx" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
<p>Slides link :</p>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/eOSyDpGElSFWvB" width="560" height="315" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/slideshow/ai-ml-infra-meetup-reducing-prefill-for-llm-serving-in-rag/269308079" title="" target="_blank">AI/ML Infra Meetup | Reducing Prefill for LLM Serving in RAG</a> </strong> </strong> </div>
    </div>

    







<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fuchi-jcl.github.io%2Fgroup-website%2Fpost%2Fjunchen_databricks%2F&amp;text=Junchen%27&#43;talk&#43;on&#43;the&#43;llm&#43;caching&#43;layer&#43;at&#43;Databricks&#43;and&#43;Alluxio%E2%80%99s&#43;AI%2FML&#43;Infra&#43;meetup.%0A" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fuchi-jcl.github.io%2Fgroup-website%2Fpost%2Fjunchen_databricks%2F&amp;t=Junchen%27&#43;talk&#43;on&#43;the&#43;llm&#43;caching&#43;layer&#43;at&#43;Databricks&#43;and&#43;Alluxio%E2%80%99s&#43;AI%2FML&#43;Infra&#43;meetup.%0A" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=Junchen%27%20talk%20on%20the%20llm%20caching%20layer%20at%20Databricks%20and%20Alluxio%E2%80%99s%20AI%2FML%20Infra%20meetup.%0A&amp;body=https%3A%2F%2Fuchi-jcl.github.io%2Fgroup-website%2Fpost%2Fjunchen_databricks%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fuchi-jcl.github.io%2Fgroup-website%2Fpost%2Fjunchen_databricks%2F&amp;title=Junchen%27&#43;talk&#43;on&#43;the&#43;llm&#43;caching&#43;layer&#43;at&#43;Databricks&#43;and&#43;Alluxio%E2%80%99s&#43;AI%2FML&#43;Infra&#43;meetup.%0A" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=Junchen%27&#43;talk&#43;on&#43;the&#43;llm&#43;caching&#43;layer&#43;at&#43;Databricks&#43;and&#43;Alluxio%E2%80%99s&#43;AI%2FML&#43;Infra&#43;meetup.%0A%20https%3A%2F%2Fuchi-jcl.github.io%2Fgroup-website%2Fpost%2Fjunchen_databricks%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fuchi-jcl.github.io%2Fgroup-website%2Fpost%2Fjunchen_databricks%2F&amp;title=Junchen%27&#43;talk&#43;on&#43;the&#43;llm&#43;caching&#43;layer&#43;at&#43;Databricks&#43;and&#43;Alluxio%E2%80%99s&#43;AI%2FML&#43;Infra&#43;meetup.%0A" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


























  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/group-website/js/vendor-bundle.min.ff7771056d34ad9f2de2d8f6a466e748.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/group-website/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/group-website/en/js/wowchemy.min.55e7d32bd4942149f880578b2c60462a.js"></script>



  <script src="/group-website/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/group-website/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js" type="module"></script>


















</body>
</html>
